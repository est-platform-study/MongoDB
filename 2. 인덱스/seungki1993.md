## 인덱스

### 단일키 인덱스
-   Document의 하나의 Key에 인덱스를 생성
-   몽고DB는 _id에 default로 인덱스가 생성 된다.
-   db.collection.createIndex( { name: -1 } )

### 복합키 인덱스
-  Document에서 하나 이상의 Key에 인덱스를 생성
-  복합 인덱스를 구성할 때 키의 순서가 중요하다.

    이름 값 인덱스| 값 이름 인덱스
    --------------|---------------|
    ace-800|800- ace
    acms-799|799 - acms
    acms-798|798 = biz
    acms-797|797 - acms
    
-   db.collection.createIndex( { name: -1 ,score : 1} )
-   복합키를 만들때 범위로 사용할 키 , 정확히 일치해야하는 키값으로 인덱스를 생성한다면 정확히 일치해야하는 키 , 범위를 위한키 순으로
     인덱스를 구성해야 한다.

### 인덱스 효율
-   인덱스가 있다면 새로운 값이 삽입 , 삭제를 한다면 인덱스안에 값을 재조정 해야한다.
-   인덱스를 생성했다고 해도 무조건 빠르게 검색하는 것은 아니다 . 심지어 더 느릴수도 있다.
-   WiredTiger 부터 도큐먼트 , 컬렉션 , 인덱스를 포함하는 데이터 파일(page)를 운영체제에 의해 램으로 스왑된다.
    -   필요한 데이터가 Ram에 올려져 있는 페이지에 있다면 해당 페이지에서 찾기 시작하겠지만
         만약 없다면 페이지 폴트를 발생시키고 디시크로 부터 데이터가 포함되어 있는 페이지를 가져온다.
    -   즉 Ram이 작을 수록 페이지 폴트가 많이 발생하며 이는 OS가 빈번하게 디스크에 액세스 한다는 이야기다
-   최소한의 인덱스만큼은 램에 들어가야 한다.
    -   즉 중복 , 필요없는 인덱스는 생성하지 말아야한다.
-   가장 이상적인 것은 인덱스와 현재 작업 중인 데이터가 모두 램에 존재해야한다
    
### B Tree
-   Balance tree
-   하나의 노드의 여러개의 키값이 있으며 각 노드에 키값으로 정렬되어 있다.
-   각 노드는 페이지에 저장이 된다.
    -   페이지 값은 정해져 있으므로 노드에 키값이 커지면 그만큼 페이지의 수가 늘어난다.
    -   페이지의 수가 늘어난다는 것은 I/O 발생이 많아지며 성능에 영향이 크다.
-   MongoDB에서 노드의 크기는 8192바이트

### 고유 인덱스
-   Document에서 고유함을 식별하기 위해 사용하는 인덱스
-   컬랙션이 비어있을때 미리 만들어 놓지 않고 중간에 만들게 되면 중복이 발생할 가능성이 있다.
-   만약 컬렉션에 이미 데이터가 존재한다면 중복값을 제거
-   db.CollectionName.createIndex({skhu:1},{unique:true})

### 희소 인덱스
-   인덱스의 키가 널이 아닌 값을 가지고 있는 도큐먼트만 존재
-   컬랙션에 인덱스를 설정하는데 인덱스를 설정하고자 하는 필드를 가진 document가 절반이상이
     null이라면 비효율적이다. 인덱스 크기가 늘어나고 , null 값임에도 인덱스를 재조정 해야한다.
-   이를 방지하기 위해 희소 인덱스를 사용하여 null 값이 아닌 document만 인덱스에 포함한다.
-   db.CollectionName.createIndex({skhu:1},{sparse:true})
-   3.2버전 부터는 희소 인덱스 보다는 partial indexes 인덱스를 사용하라고 권장함

### 다중키 인덱스
-   필드의 값이 배열이 경우에 배열 원소의 인덱스를 건다
-   다중 키 인덱스를 생성 , 업데이트 , 샂게하는 것은 단일 키 인덱스를 생성 , 업데이트 , 삭제하는 것 보다 많은 비용 발생
-   unique 속성이랑 같이 사용시 당연히 저장이 안됨
-   둘 이상의 필드가 배열이면 사용 할 수 없다.

### Hash 인덱스
-   해시 함수를 통해 만들어진 해시값으로 인덱스를 생성하는 방식
-   해시된 값으로 순서를 결정
-   범위 쿼리 지원 x
-   다중 키는 해쉬 적용이 안된다.
-   부동 소수점 값은 해시되기 전에 정수로 되기 때문에 문제가 발생
-   db.collectioName.createIndex({recipe_name:'hashed'})
-   샤드를 결정하는 샤드 컬랙션에 유용하다.

### 지리적 공간적 인덱스
-   지구의 곡률을 포함하여 지리적 거리를 효율적으로 계산할 수 있는 인덱스

### 인덱스 구축
-   대량의 데이터가 들어있는 컬렉션에 인덱스를 걸게 되면 오랜 시간이 걸린다.
-   인덱스 과정
    -   인덱스할 값을 정렬한다.
    -   정렬된 값이 인덱스로 삽입된다.
-   서버 로그르 확인하면 정렬 , 삽입에 대한 진척도를 할 수 있으며 셸의 currentOp()메서드로도 확인 할 수 있다.
-   인덱스가 생성되는 동안에는 데이터베이스에 읽거나 쓰기를 할 수 없다.

### 백그라운드 인덱싱
-   기본적으로 인덱스를 생성할때 데이터 베이스에 읽거나 쓰기를 할 수 없다.
-   백그라운드 인덱싱은 이러한 문제점을 해결하기 위한 해결책
-   인덱스를 백그라운드에서 구축되도록 하는 방식
    -   하지만 쓰기 잠근은 지속
-   db.test.createIndex({open : 1,close : 1},{background: true})

### 오프라인 인덱싱
-   복제 노드를 오프란인 상태를 만든 후 인덱싱을 직압을 하고 마스터로 부터 업데이트를 받는다.
-   업데이트가 완료되면 해당 노드를 마스터 노드로 전환하고 나머지 노드에 인덱스를 구축한다.
-   오프라인 노드에 인덱스를 구축하는 동안 데이터가 손상 되는것을 막을 정도록 복제 oplog가 커여한다.
-   oplog
    -   마스터에 들어오는 모든 요청들을 기록하는 파일
    -   기본 사이즈
        -    unix or window에서는 5% of free disk space
        -   macOS   192MB of free disk spacce
        
### 백업
-   백업은 인덱스를 포함하지 않는다(mongodump , mongorestore)
    -   해당 유틸리티는 컬랙션과 인덱스의 정의만을 보관
    -   즉 데이터를 백업하게 되면 인덱스를 다시 해줘야 한다.
-   백업이 인덱스를 포함하길 원한다면 데이터 파일 자체를 백업해야한다.

### DEFRAGMENTING
-   기존 데이터의 업데이트나 대량의 데이터 삭제가 자주 발생한다면 인덱스가 단편화가 된다.
-   B tree가 내부적으로 재구성을 하지만 완벽하게 하지는 못한다.
-   해결책은 인덱싱을 재 인덱싱 하는 것이다.
-   재 인덱싱 동안 스기 잠금을 수행하기 때문에 오프라인일때 최적이다.
-   reindex 작업 자체가 너무 무겁다
-   doucment 상에서는 대부분의 유저는 사용할 이유가 없으며 복제세트와 샤트 클러스터에서 사용하지 말라고 되어 있다.
-   4.0 부터는 리인덱스 하는동안 아무 작업도 할 수 가없다.

### 쿼리 최적화
#### 느린 쿼리 탐지
-   MongoDB logger 는 쿼리가 100밀리초 이내에 실행 된다고 가정하여 해당 시간이 지나면 경고 메시지를 프린트 한다.
    -   옵션을 통해 변경 가능
    -   로그를 통해 찾는 것은 정교하지 못하기에 점검장치로만 사용
-   프로파일러 느린 쿼리를 찾기 위한 정확한 툴
-   프로파일러는 내장된 툴
    -   use test // test database
    -   db.setProfilingLevel()
    -   level
        -   0   비활성화 (default)
        -   1   오래걸리는 작업에 대한 데이터를 수집
        -   2   모든 작업에 대한 수집
    -   수집된 데이터는 system.profile이라고 부르는 특수한 컬랙션에 저장
    -   프로파일을 통해 검사할때는 한번에 작은 시간이 아닌 절차적인 시간을 줄여가면서 확인한다.
    -   프로파일을 할때 읽기/쓰기가 가능한지 테스트 해야한다.
    -   시간이 얼마나 걸렸는지는 알 수 있으나 이유를 발견하기는 쉽지 않다(추측 및 추리력 필요)
-   역시 explain
    -   mongo나 rdb나 explain
    -   쿼리에 대한 자세한 경로를 제공
    -   주요 정보
        -   nscanned
            -   몇개의 document를 검색 했는지
            -   즉 쿼리의 최적화는 nscanned를 최소화 하는 것이다.
-   optimizer가 인덱스를 선택한다.
    -   옵티마이저는 쿼리에 대한 인덱스가 여러개라면 옵티마이저는
         병렬로 각 플랜을 실행하고 완료후에 nscanned가 최소값을 갖는 플랜을 선택한다.
-   explain 속성으로 true로 하면 옵티마이저가 시도하는 플랜의 리스트를 포함한다.

-   옵티마이저가 모든 플랜을 매번 하는것은 비효율적이기 때문에 성공적인 패턴이 발견되면 쿼리 패턴 , nscanned의 값
     , 인덱스의 규격이 기록된다.
     -  새로운 쿼리가 해당 패턴에 일치하면 해당 플랜을 사용한다.
     -  계속 캐시해서 가지고 있지 않다.
        -   컬랙션에 대해 100회의 쓰기 실행
        -   컬랙션에 인덱스가 추가되거나 삭제
        -   캐시플랜을 사용했는데 예상보다 많은 작업을 수행
            -   캐시에 저장되어 있는 nscanned에 수보다 10배 이상의 nscanned을 반환할 경우


### 커버링 인덱스
-   인덱스의 종류가 아니다
-   covered index query 라고 생각
    -   covered index query는 쿼리에 사용되는 모든 필드가 인덱스된 필드만 포함이 된다면
         도큐먼트를 스캔하지 않고 인덱스에서 결과를 도출한다.
            